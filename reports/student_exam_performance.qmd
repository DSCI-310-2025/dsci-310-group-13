---
title: "Predicting and Understanding what leads to High Knowledge Levels"
author: "Adam Walmsley, Morgan Dean, Tracy Wang, Yuexiang Ni"
format:
  html:
    toc: true  # Enables automatic table of contents
    toc-title: "Table of Contents"
    number-depth: 3
    number-sections: true  # Numbers the sections
    fig-cap-location: top
    toc-location: left
    embed-resources: true
editor: source
bibliography: references.bib
execute:
  echo: false
  warning: false
  message: false
  error: false
---

## **Declaration**

Our research project utilized the DSCI100 project (@anthony2022).

It was originally completed by one of our members, with consent from all his teammates.

## **Summary**

In this study we look at how exam performance and time spent studying affect user knowledge on a specific application area. We see if we can build a regression model to accurately predict this user knowledge, and which if any of the two features are more important in building an accurate model.

## **Introduction**

Understanding how study time and exam performance contribute to a student's knowledge level is crucial in educational research (@timbers2022). In this study, we analyze data from the User Knowledge Modeling Dataset retrieved from the UCI machine learning repository database with the CC BY 4.0 license (@kahraman2013). It was collected from undergraduate students in the Faculty of Technology at Gazi University. The dataset, available from the UCI Machine Learning Repository, was originally developed to assess intuitive knowledge classifiers using study behaviors and performance metrics (@kahraman2012).  

The dataset consists of six key variables:  
- STG: Degree of study time for goal object materials  
- SCG: Degree of repetition for goal object materials  
- STR: Degree of study time for related objects with goal object  
- LPR: Exam performance of the user for related objects with goal object  
- PEG: Exam performance of the user for goal objects  
- UNS: Knowledge level of the user (categorical target variable)  

For this study, we focus on STG (study time for goal object materials)** and PEG (exam performance for goal objects)** as primary predictors of student knowledge, represented by the UNS variable, which is classified into four categories: Very Low, Low, Middle, and High. Our objective is to determine whether time spent studying or actual exam performance is a stronger indicator of student knowledge. In other words, from this data we can use study time, and exam performance to predict our own user’s knowledge level and test which is a better determining factor to knowledge level, study time or exam performance. We decided to use these two variables to determine user knowledge because we were curious on what mattered most for students’ knowledge level, study time or how they performed on the exam. This will also in turn let us understand if exams taken place actually evaluate what they are supposed to. If proven we will be able to  implement our model onto similar evaluations at any university to determine if exams are in fact relevant to real-world learnings.

### Question: 
Which habit/result is more indicative of a student's knowledge level: the time they spent studying or their actual exam results? <br/>

## **Methods and Results**

### Preliminary exploratory data analysis:

The dataset being used is User Knowledge Modeling Data Set and includes factors that measured the study time of more and less specific information for an exam as well as study repetition of this material. Exam performance on specific and less specific information was also measured. These factors were recorded on a scale from 0.00 to 1.00. These observations were then used to determine the target value of the knowledge level which was categorized with very low, low, middle and high. 

To begin answering our question, we began by loading the required packages.

```{r}
library(kknn)
library(tidyverse)
library(repr)
library(tidymodels)
library(readxl)
library(knitr)
library(rmarkdown)
library(MASS)
library(ggplot2)
library(caret)
library(docopt)
```

Since the data set was an excel file and came from the web, we used the ```download.file``` function to download and convert the data from its original format to something we could work with and analyze. The excel also contained several sheets and was already split up into training and test data, which we used to create our training and test variables. The word format was inconsistent between sheets; the training data's user knowledge level was typed in lowercase and with underscores, and the test data's user knowledge level was typed in regular case and with spaces. So to ensure consistency between data, we converted the "Very Low" value into "very_low." The data was already standardized and so this step was not required here.

```{r}
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/00257/Data_User_Modeling_Dataset_Hamdi%20Tolga%20KAHRAMAN.xls"
data_file <- "../data/data.xls"
#download.file(url, data_file, mode = 'wb')
knowledge_train_data <- read_excel(data_file, 2)
knowledge_test_data <- read_excel(data_file, 3)
knowledge_test_data[knowledge_test_data == "Very Low"] <- "very_low"
```

With our data now loaded in, we select the specific columns (which include our predictors and classifier variables) from the data set. These columns include the User Knowledge Level (UNS, the classification variable), Study Time for Goal Object Materials (STG, a predictor), and Exam Performance for Goal Object (PEG, another predictor). Because the UNS column contains the classification groups, we mutated this from a string to an ordinal factor data type. We loaded the first couple of rows from each table to observe these changes. (See @tbl-knowledge_train_data and @tbl-knowledge_test_data below)

```{r create train/test split}
knowledge_train_data <- knowledge_train_data %>%
    mutate(UNS = factor(UNS, 
                        levels = c("very_low", "Low", "Middle", "High"), 
                        ordered = TRUE)) %>%
    dplyr::select(STG, PEG, UNS) %>%
    drop_na()

knowledge_test_data <- knowledge_test_data %>%
    mutate(UNS = factor(UNS, 
                        levels = c("very_low", "Low", "Middle", "High"), 
                        ordered = TRUE)) %>%
    dplyr::select(STG, PEG, UNS) %>%
    drop_na()

```

```{r load-all-data}
# Load all preprocessed data
knowledge_train_data <- read_csv("../results/table1.csv")
knowledge_test_data <- read_csv("../results/table2.csv")
know_percentage_train <- read_csv("../results/table3.csv")
know_percentage_test <- read_csv("../results/table4.csv")
knowledge_train_summary <- read_csv("../results/table5.csv")
ordinal_model <- read_csv("../results/table6.txt")
accuracy <- read_csv("../results/table7.txt")
```


```{r Display Train}
#| label: tbl-knowledge_train_data
#| tbl-cap: "First six rows of the Training Data"
knitr::kable(knowledge_train_data)
```

```{r Display Test}
#| label: tbl-knowledge_test_data
#| tbl-cap: "First six rows of the Testing Data"
knitr::kable(knowledge_test_data)
```

Next, we wanted to see the distribution of knowledge levels within the training and testing data, so we grouped the data by the knowledge level, found their counts, and then calculated the percent of each class. From @tbl-know_percentage_train, we can see that `r round(know_percentage_train$percentage[know_percentage_train$UNS == "very_low"], 0)`% of users have a very low knowledge level, `r round(know_percentage_train$percentage[know_percentage_train$UNS == "High"], 0)`% have a high knowledge level, `r round(know_percentage_train$percentage[know_percentage_train$UNS == "Low"], 0)`% have a low knowledge level, and `r round(know_percentage_train$percentage[know_percentage_train$UNS == "Middle"], 0)`% have a middle knowledge level. @tbl-know_percentage_test (testing data) on the other hand, shows that `r round(know_percentage_test$percentage[know_percentage_test$UNS == "very_low"], 0)`% of users have a very low knowledge level, `r round(know_percentage_test$percentage[know_percentage_test$UNS == "High"], 0)`% have a high knowledge level, `r round(know_percentage_test$percentage[know_percentage_test$UNS == "Low"], 0)`% have a low knowledge level, and `r round(know_percentage_test$percentage[know_percentage_test$UNS == "Middle"], 0)`% have a middle knowledge level. We will have to keep these differences in mind during the randomization process and as we conduct further analysis.

```{r train data info}
#| label: tbl-know_percentage_train
#| tbl-cap: "Count and Percent of User Knowledge Levels in the training data."
knitr::kable(know_percentage_train)
```

```{r test data info}
#| label: tbl-know_percentage_test
#| tbl-cap: "Count and Percent of User Knowledge Levels in the testing data."
knitr::kable(know_percentage_test)
```

We still wanted to understand our data a bit more. To do so, we wrangled the training data a bit more to generate a table of the mean STG and PEG and the minimum and maximum values of the predictors for each knowledge level. This helped us get a sense of the boundaries for each class and the variance within each predictor (See @tbl-knowledge_train_summary below).

```{r summarize data}
#| label: tbl-knowledge_train_summary
#| tbl-cap: "Means, Minimums, and Maximums of Selected Variables in Training Data"
knitr::kable(knowledge_train_summary)
```

All these tables helped us understand the data but still required attentive interpretation. So we now created a visualization of the User Knowledge Level distribution based on the Exam Performance and Study Time variables. The plot below shows how the knowledge levels are stacked vertically like layers, where study time can vary from 0 to 1 for each class, but the exam performance imposes somewhat of a boundary on each category (See @fig-knowledge_train_summary below).

![Visualization of the distribution of Knowledge Levels based on Exam Performance and Study Time.](../results/fig1.png){#fig-knowledge_train_summary width=80%}

### Main Analysis and Results

In this analysis we chose to use the machine learning method of ordinal logistic regression. Since this is a multi classification problem we could not use simple binary logistic regression. We begin by fitting our model and looking at the coefficients on each feature.

```{r Fit Model}
#| label: tbl-ordinal_model
#| tbl-cap: "Summary across included features in our fitted model"
knitr::kable(ordinal_model)
```

From @tbl-ordinal_model we see that exam performance has a coefficient nearly fifty times the degree of study indicating the feature is much more indicative of user knowledge. Now we have to see if this model performs well on the test data

```{r Predict on test data}
#| label: tbl-accuracy
#| tbl-cap: "Model Accuracy"
knitr::kable(accuracy)
```

Our model produces a mean accuracy of 82% which is promising (see @tbl-accuracy). This means that really only using exam grade as a feature allows ordinal regression to achieve high accuracy across this complex problem.

Next we produce some visualizations to get a better sense of the data.

![Confusion Matrix](../results/fig2.png){#fig-confusion_matrix width=80%}

This confusion matrix (@fig-confusion_matrix) tells us where our model is predicting correctly and incorrectly, as well as the frequency to which it does that. We can see that across all possible classes it is fairly successful with some slight confusion being introduced when comparing the 'low' and 'very low' classes.

![Feature Importance](../results/fig3.png){#fig-feature_inportance width=80%}

In @fig-feature_inportance we again look at how much importance our model gave to each of the features we included. As seen during fitting, exam grades is given the vast majority of the weighting and is practically the sole predictor for our model.

## **Discussion**

During this analysis we found a model that successfully predicts user knowledge separated by four distinct classes. We saw that when using degree of study time and exam performance as features, exam performance was by far the most useful predictor and dominated the model. This was an unexpected result in terms of the magnitude of importance. We thought that exam performance would probably be the most useful feature out of the two, but not by so much. This shows that the exams taken where this study was conducted is indeed a tell tale sign of user knowledge and that time spent studying, which may increase exam performance, does not tell us much about the users knowledge. 

The impacts this study could bring about are vast. By performing a similar result at other institutions it could be a way of confirming if their testing procedures are representative of real life skills. This is something every test maker hopes to achieve and could be substantiated by a similar result as in this study. 

In the future this could lead to questions regarding what else is indicative of user knowledge other than exam performance. Are there other indicators more important than exam performance?

We would also like to state that to improve this studies reliability we could make some or all of the following improvements. We could use cross validation to increase the confidence of our results, include more features to build a more robust and accurate model, and test out other regression techniques.

## **Assumptions and Limitations**

In this study we determined a model that can classify students into one of four categories for student performance based on a few metrics. We acknowledge that our model was only applied to a single dataset from one university and extracting these results and methods to new datasets will yield different results that are out of our scope. We also assumed that all data was taken in a random, unbiased manor from Gazi University.

## **Reference**